{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantaris Data - Training\n",
    "\n",
    "The training process was aimed to be simple enough to get the main idea of the whole process.\n",
    "There are many optimizations and variations that can be done to the whole process, but they are out of the scope of this talk focused on beginners.\n",
    "\n",
    "In summary, the model consist on:\n",
    "* A pretrained [ResNet50](https://pytorch.org/docs/stable/torchvision/models.html) CNN\n",
    "* Modification to the final layer to adopt the decision to the current categories\n",
    " *  A Sequential layer with: Linear, ReLU, Dropout, Linear, LogSoftmax\n",
    "* A [negative log likelihood loss (NLLLoss)](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html), since it's useful for classification problem with N classes.\n",
    "* [Adam optimization](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "data_dir = \"data_all\"\n",
    "\n",
    "# Note that resnet50 requires 224 minimum\n",
    "SIZE = 256\n",
    "\n",
    "# Fixed seed\n",
    "np.random.seed(30011986)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the train and test data\n",
    "\n",
    "This process relies on the `ImageFolder` function, to base both sets from the directories with our labeled images.\n",
    "## Transformations\n",
    "The transformations are not require to be the same for both sets, but the `Resize` and `Normalize` are required in in the *test* if it was used on the *train*, otherwise the verification steps will not work.\n",
    "Since one of the features of detecting a plant that needs watering is that the leaves are a bit tilted, the *Rotate* transformation was not considered.\n",
    "Due to the nature of these *real images*, a `CenterCrop` makes sense, to avoid all the noise from the rest of the image besides the plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir, valid_size=0.2):\n",
    "\n",
    "    # Transformations for Training\n",
    "    transformations = [\n",
    "        transforms.Resize((SIZE, SIZE)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "    train_transforms = transforms.Compose(transformations)\n",
    "\n",
    "    # Transformations for Testing\n",
    "    test_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((SIZE, SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
    "\n",
    "    # Splitting the data\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=64\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_data, sampler=test_sampler, batch_size=64\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases ['ok', 'other', 'watering']\n",
      "Length trainloader: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /Users/mariajosemolina/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = load_split_train_test(data_dir)\n",
    "print(\"Clases\", trainloader.dataset.classes)\n",
    "print(\"Length trainloader:\", len(trainloader))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze parameters, to avoid backpropagation through them.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modifying the final layer of the CNN\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 3),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)\n",
    "\n",
    "epochs = 20\n",
    "running_loss = 0\n",
    "print_every = 2\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training...\")\n",
    "time_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for steps, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss / len(trainloader))\n",
    "            test_losses.append(test_loss / len(testloader))\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\"\n",
    "            )\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "print(\"Training time:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "if os.path.isfile(f\"trained_model_{data_dir}.pth\"):\n",
    "    print(\"The trained model file exists, creating a second\")\n",
    "    torch.save(model, f\"trained_model_{data_dir}.pth.2\")\n",
    "else:\n",
    "    torch.save(model, f\"trained_model_{data_dir}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure\n",
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(test_losses, label=\"Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(\"Figure_all2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
